
# Dasar-dasar Prompting

import {Screenshot} from 'components/screenshot'
import INTRO1 from '../../img/introduction/sky.png'
import {Bleed} from 'nextra-theme-docs'

## Memberikan Prompt kepada LLM

Anda bisa mencapai banyak hal dengan prompt sederhana, tetapi kualitas hasilnya tergantung pada seberapa banyak informasi yang Anda berikan dan seberapa baik prompt tersebut dirancang. Sebuah prompt bisa berisi informasi seperti *instruksi* atau *pertanyaan* yang Anda berikan ke model, serta detail lain seperti *konteks*, *input*, atau *contoh*. Anda bisa menggunakan elemen-elemen ini untuk menginstruksikan model dengan lebih efektif guna meningkatkan kualitas hasil.

Mari kita mulai dengan melihat contoh dasar prompt sederhana:

*Prompt*

```md
Langit itu
```

*Output:*
```md
biru.
```

Jika Anda menggunakan OpenAI Playground atau playground LLM lainnya, Anda bisa memberikan prompt ke model seperti yang ditunjukkan pada tangkapan layar berikut:

<Screenshot src={INTRO1} alt="INTRO1" />

Berikut adalah tutorial cara memulai dengan OpenAI Playground:

<iframe width="100%"
  height="415px"
  src="https://www.youtube.com/embed/iwYtzPJELkk?si=irua5h_wHrkNCY0V" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture"
  allowFullScreen
  />

Perlu diingat bahwa ketika menggunakan model chat OpenAI seperti `gpt-3.5-turbo` atau `gpt-4`, Anda bisa menyusun prompt Anda menggunakan tiga peran berbeda: `system`, `user`, dan `assistant`. Pesan sistem tidak wajib, tetapi membantu mengatur perilaku keseluruhan asisten. Contoh di atas hanya mencakup pesan pengguna yang bisa Anda gunakan untuk langsung memberikan prompt ke model. Untuk kesederhanaan, semua contoh, kecuali disebutkan secara eksplisit, hanya akan menggunakan pesan `user` untuk memberikan prompt ke model `gpt-3.5-turbo`. Pesan `assistant` dalam contoh di atas sesuai dengan respons model. Anda juga bisa menentukan pesan asisten untuk memberikan contoh perilaku yang diinginkan. Anda bisa mempelajari lebih lanjut tentang bekerja dengan model chat [di sini](https://www.promptingguide.ai/models/chatgpt).

Dari contoh prompt di atas, Anda bisa melihat bahwa model bahasa merespons dengan urutan token yang masuk akal berdasarkan konteks "Langit itu". Hasilnya mungkin tidak terduga atau jauh dari tugas yang ingin Anda capai. Sebenarnya, contoh dasar ini menunjukkan perlunya memberikan lebih banyak konteks atau instruksi tentang apa yang ingin Anda capai dengan sistem tersebut. Inilah yang disebut dengan prompt engineering.

Mari coba memperbaikinya sedikit:

*Prompt:*
```
Lengkapi kalimat berikut: 

Langit itu
```

*Output:*

```
biru di siang hari dan gelap di malam hari.
```

Apakah itu lebih baik? Ya, dengan prompt di atas Anda menginstruksikan model untuk melengkapi kalimat, sehingga hasilnya terlihat jauh lebih baik karena mengikuti persis apa yang Anda katakan (melengkapi kalimat). Pendekatan merancang prompt yang efektif untuk menginstruksikan model melakukan tugas yang diinginkan inilah yang disebut **prompt engineering** dalam panduan ini.

Contoh di atas adalah ilustrasi sederhana tentang apa yang mungkin dilakukan dengan LLM saat ini. LLM modern mampu melakukan berbagai tugas canggih mulai dari meringkas teks, penalaran matematika, hingga menghasilkan kode.

## Format Prompt

Anda telah mencoba prompt yang sangat sederhana di atas. Sebuah prompt standar memiliki format berikut:

```
<Pertanyaan>?
```

atau 

```
<Instruksi>
```
 
Anda bisa memformatnya menjadi format tanya jawab (QA), yang standar di banyak dataset QA, sebagai berikut:

```
T: <Pertanyaan>?
J: 
```

Ketika memberikan prompt seperti di atas, ini juga disebut sebagai *prompting zero-shot*, yaitu Anda langsung memberikan prompt ke model untuk mendapatkan respons tanpa contoh atau demonstrasi tentang tugas yang ingin Anda capai. Beberapa model bahasa besar memiliki kemampuan untuk melakukan prompting zero-shot, tetapi tergantung pada kompleksitas dan pengetahuan tentang tugas yang dihadapi dan tugas-tugas yang dilatih model untuk dikerjakan dengan baik.

Contoh prompt konkret adalah sebagai berikut:

*Prompt*
```
T: Apa itu prompt engineering?
```

Dengan beberapa model yang lebih baru, Anda bisa melewatkan bagian "T:" karena sudah tersirat dan dipahami oleh model sebagai tugas tanya jawab berdasarkan bagaimana urutan disusun. Dengan kata lain, prompt bisa disederhanakan sebagai berikut:

*Prompt*
```
Apa itu prompt engineering?
```

Berdasarkan format standar di atas, salah satu teknik populer dan efektif untuk prompting disebut *few-shot prompting* di mana Anda memberikan contoh (yaitu, demonstrasi). Anda bisa memformat prompt few-shot sebagai berikut:

```
<Pertanyaan>?
<Jawaban>

<Pertanyaan>?
<Jawaban>

<Pertanyaan>?
<Jawaban>

<Pertanyaan>?

```

Versi format QA akan terlihat seperti ini:

```
T: <Pertanyaan>?
J: <Jawaban>

T: <Pertanyaan>?
J: <Jawaban>

T: <Pertanyaan>?
J: <Jawaban>

T: <Pertanyaan>?
J:
```

Perlu diingat bahwa tidak wajib menggunakan format QA. Format prompt tergantung pada tugas yang dihadapi. Misalnya, Anda bisa melakukan tugas klasifikasi sederhana dan memberikan contoh yang mendemonstrasikan tugas tersebut sebagai berikut:

*Prompt:*
```
Ini luar biasa! // Positif
Ini buruk! // Negatif
Wow film itu keren! // Positif
Acara yang mengerikan! //
```

*Output:*
```
Negatif
```

Prompt few-shot memungkinkan pembelajaran dalam konteks, yaitu kemampuan model bahasa untuk mempelajari tugas-tugas yang diberikan beberapa demonstrasi. Kami membahas prompting zero-shot dan few-shot secara lebih mendalam di bagian-bagian selanjutnya.

