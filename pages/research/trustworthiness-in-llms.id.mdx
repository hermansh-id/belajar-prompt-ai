
# Kepercayaan pada LLM (Model Bahasa Besar)

import {Screenshot} from 'components/screenshot'

import TRUSTLLM from '../../img/llms/trustllm.png'
import TRUSTLLM2 from '../../img/llms/trust-dimensions.png'
import TRUSTLLM3 from '../../img/llms/truthfulness-leaderboard.png'

LLM yang dapat dipercaya sangat penting untuk membangun aplikasi di bidang-bidang kritis seperti kesehatan dan keuangan. Meskipun LLM seperti ChatGPT sangat mampu menghasilkan respons yang mudah dibaca manusia, mereka tidak menjamin respons yang dapat dipercaya dalam berbagai aspek seperti kebenaran, keamanan, dan privasi.

[Sun dkk. (2024)](https://arxiv.org/abs/2401.05561) baru-baru ini mengusulkan studi komprehensif tentang kepercayaan pada LLM, membahas tantangan, tolok ukur, evaluasi, analisis pendekatan, dan arah masa depan.

Salah satu tantangan terbesar dalam menggunakan LLM saat ini adalah masalah kepercayaan. Survei mereka mengusulkan serangkaian prinsip untuk LLM yang dapat dipercaya yang mencakup 8 dimensi, termasuk tolok ukur di 6 dimensi (kebenaran, keamanan, keadilan, ketahanan, privasi, dan etika mesin).

Penulis mengusulkan tolok ukur berikut untuk mengevaluasi kepercayaan LLM dalam enam aspek:

<Screenshot src={TRUSTLLM} alt="Tolok ukur model bahasa besar yang dapat dipercaya" />

Berikut adalah definisi dari delapan dimensi LLM yang dapat dipercaya:

<Screenshot src={TRUSTLLM2} alt="Dimensi LLM yang Dapat Dipercaya" />

## Temuan

Penelitian ini juga menyajikan studi yang mengevaluasi 16 LLM utama dalam TrustLLM, terdiri dari lebih dari 30 dataset. Berikut adalah temuan utama dari evaluasi tersebut:

- Meskipun LLM proprietary (milik perusahaan) umumnya mengungguli sebagian besar LLM open-source dalam hal kepercayaan, ada beberapa model open-source yang mulai memperkecil kesenjangan.
- Model seperti GPT-4 dan Llama 2 dapat secara andal menolak pernyataan stereotip dan menunjukkan ketahanan yang lebih baik terhadap serangan yang disengaja.
- Model open-source seperti Llama 2 berkinerja hampir setara dengan model proprietary dalam hal kepercayaan tanpa menggunakan alat moderasi khusus. Disebutkan juga dalam makalah bahwa beberapa model, seperti Llama 2, terlalu dikalibrasi untuk kepercayaan yang terkadang mengorbankan kegunaannya pada beberapa tugas dan secara keliru memperlakukan prompt yang tidak berbahaya sebagai input yang berbahaya bagi model.

## Wawasan Utama

Dari berbagai dimensi kepercayaan yang diteliti dalam makalah tersebut, berikut adalah wawasan utama yang dilaporkan:

- **Kebenaran**: LLM sering kesulitan dengan kebenaran karena noise data pelatihan, informasi yang salah, atau informasi yang sudah usang. LLM dengan akses ke sumber pengetahuan eksternal menunjukkan kinerja yang lebih baik dalam hal kebenaran.

- **Keamanan**: LLM open-source umumnya tertinggal dari model proprietary dalam aspek keamanan seperti jailbreak (pembobolan), konten beracun, dan penyalahgunaan. Ada tantangan dalam menyeimbangkan langkah-langkah keamanan tanpa terlalu berhati-hati.

- **Keadilan**: Sebagian besar LLM berkinerja kurang memuaskan dalam mengenali stereotip. Bahkan model canggih seperti GPT-4 hanya memiliki akurasi sekitar 65% di bidang ini.

- **Ketahanan**: Ada variabilitas yang signifikan dalam ketahanan LLM, terutama dalam tugas-tugas terbuka dan di luar distribusi.

- **Privasi**: LLM menyadari norma-norma privasi, tetapi pemahaman dan penanganan informasi pribadi mereka sangat bervariasi. Sebagai contoh, beberapa model telah menunjukkan kebocoran informasi ketika diuji pada Dataset Email Enron.

- **Etika Mesin**: LLM menunjukkan pemahaman dasar tentang prinsip-prinsip moral. Namun, mereka masih kurang dalam skenario etika yang kompleks.

## Papan Peringkat Kepercayaan untuk LLM

Penulis juga telah mempublikasikan papan peringkat [di sini](https://trustllmbenchmark.github.io/TrustLLM-Website/leaderboard.html). Sebagai contoh, tabel di bawah ini menunjukkan bagaimana model-model yang berbeda diukur pada dimensi kebenaran. Seperti yang disebutkan di situs web mereka, "LLM yang lebih dapat dipercaya diharapkan memiliki nilai metrik yang lebih tinggi dengan ↑ dan nilai yang lebih rendah dengan ↓".

<Screenshot src={TRUSTLLM3} alt="Papan Peringkat Kepercayaan untuk LLM" />

## Kode

Anda juga dapat menemukan repositori GitHub dengan kit evaluasi lengkap untuk menguji kepercayaan LLM di berbagai dimensi.

Kode: https://github.com/HowieHwong/TrustLLM

## Referensi

Sumber Gambar / Makalah: [TrustLLM: Trustworthiness in Large Language Models](https://arxiv.org/abs/2401.05561) (10 Jan 2024)
