

# Menghasilkan Dataset Sintetis untuk RAG

import {Screenshot} from 'components/screenshot'
import remarkMath from 'remark-math'
import rehypeKatex from 'rehype-katex'

import IMG1 from '../../../img/synthetic_rag/synthetic_rag_1.png'
import IMG2 from '../../../img/synthetic_rag/synthetic_rag_2.png'
import IMG3 from '../../../img/synthetic_rag/synthetic_rag_3.png'
import IMG4 from '../../../img/synthetic_rag/synthetic_rag_4.png'

## Persiapan Data Sintetis untuk RAG

Dalam dunia Rekayasa Pembelajaran Mesin (Machine Learning Engineering), sering kali kita menghadapi masalah kekurangan data berlabel atau data yang sangat terbatas. Biasanya, ketika menyadari hal ini, proyek-proyek akan memulai proses panjang pengumpulan dan pelabelan data. Baru setelah beberapa bulan, pengembangan solusi bisa dimulai.

Namun, dengan munculnya Model Bahasa Besar (Large Language Models atau LLM), cara kerja ini berubah untuk beberapa produk: sekarang kita bisa memanfaatkan kemampuan generalisasi LLM dan menguji ide atau mengembangkan fitur berbasis AI hampir secara instan. Jika hasilnya (hampir) sesuai harapan, maka proses pengembangan tradisional bisa dimulai.

<Screenshot src={IMG1} alt="Perubahan paradigma dalam produk berbasis AI." />

Sumber Gambar: [The Rise of the AI Engineer, oleh S. Wang](https://www.latent.space/p/ai-engineer)

Salah satu pendekatan yang sedang berkembang adalah [Retrieval Augmented Generation (RAG)](https://www.promptingguide.ai/techniques/rag). RAG digunakan untuk tugas-tugas yang membutuhkan pengetahuan intensif di mana kita tidak bisa hanya mengandalkan pengetahuan model. RAG menggabungkan komponen pencarian informasi dengan model pembangkit teks. Untuk mempelajari lebih lanjut tentang pendekatan ini, lihat [bagian yang relevan dalam panduan](https://www.promptingguide.ai/techniques/rag).

Komponen utama RAG adalah model Retrieval (Pencarian) yang mengidentifikasi dokumen-dokumen relevan dan meneruskannya ke LLM untuk diproses lebih lanjut. Semakin baik kinerja model Retrieval, semakin baik hasil produk atau fiturnya. Idealnya, Retrieval bekerja dengan baik sejak awal. Namun, kinerjanya sering menurun dalam bahasa yang berbeda atau domain tertentu.

Bayangkan situasi ini: Anda perlu membuat chatbot yang menjawab pertanyaan berdasarkan hukum dan praktik hukum Republik Ceko (dalam bahasa Ceko, tentu saja). Atau merancang asisten pajak (kasus penggunaan yang dipresentasikan oleh OpenAI selama presentasi GPT-4) yang disesuaikan untuk pasar India. Kemungkinan besar Anda akan menemukan bahwa model Retrieval sering melewatkan dokumen yang paling relevan dan secara keseluruhan tidak berkinerja sebaik yang diharapkan, sehingga membatasi kualitas sistem.

Tapi ada solusinya. Tren yang sedang berkembang melibatkan penggunaan LLM yang ada untuk mensintesis data untuk pelatihan generasi baru LLM/Retriever/model lainnya. Proses ini dapat dilihat sebagai penyulingan LLM menjadi encoder berukuran standar melalui pembuatan query berbasis prompt. Meskipun penyulingan ini membutuhkan komputasi yang intensif, hal ini secara substansial mengurangi biaya inferensi dan mungkin sangat meningkatkan kinerja, terutama dalam bahasa dengan sumber daya rendah atau domain khusus.

Dalam panduan ini, kita akan mengandalkan model generasi teks terbaru, seperti ChatGPT dan GPT-4, yang dapat menghasilkan sejumlah besar konten sintetis sesuai instruksi. [Dai et al. (2022)](https://arxiv.org/abs/2209.11755) mengusulkan metode di mana dengan hanya 8 contoh yang dilabeli secara manual dan korpus besar data yang tidak berlabel (dokumen untuk pencarian, misalnya, semua undang-undang yang diuraikan), seseorang dapat mencapai kinerja hampir setara dengan State-of-the-Art. Penelitian ini mengkonfirmasi bahwa data yang dihasilkan secara sintetis memfasilitasi pelatihan retriever khusus tugas untuk tugas-tugas di mana fine-tuning dalam domain yang diawasi merupakan tantangan karena kelangkaan data.

## Pembuatan Dataset Khusus Domain

Untuk memanfaatkan LLM, seseorang perlu memberikan deskripsi singkat dan melabeli beberapa contoh secara manual. Penting untuk dicatat bahwa tugas pencarian yang berbeda memiliki maksud pencarian yang berbeda, yang berarti definisi "relevansi" yang berbeda. Dengan kata lain, untuk pasangan (Query, Dokumen) yang sama, relevansi mereka mungkin berbeda sama sekali berdasarkan maksud pencarian. Misalnya, tugas pencarian argumen mungkin mencari argumen pendukung, sementara tugas lain memerlukan argumen tandingan (seperti yang terlihat dalam [dataset ArguAna](https://aclanthology.org/P18-1023/)).

Perhatikan contoh di bawah ini. Meskipun ditulis dalam bahasa Inggris untuk pemahaman yang lebih mudah, ingatlah bahwa data dapat dalam bahasa apa pun karena ChatGPT/GPT-4 secara efisien memproses bahkan bahasa dengan sumber daya rendah.

*Prompt:*
```
Tugas: Identifikasi argumen tandingan untuk argumen yang diberikan.

Argumen #1: {masukkan bagian X1 di sini}

Query argumen tandingan yang ringkas terkait dengan argumen #1: {masukkan query Y1 yang disiapkan secara manual di sini}

Argumen #2: {masukkan bagian X2 di sini}
Query argumen tandingan yang ringkas terkait dengan argumen #2: {masukkan query Y2 yang disiapkan secara manual di sini}

<- tempelkan contoh Anda di sini ->

Argumen N: Bahkan jika denda dibuat proporsional dengan pendapatan, Anda tidak akan mendapatkan kesetaraan dampak yang Anda inginkan. Ini karena dampaknya tidak hanya proporsional dengan pendapatan, tetapi harus memperhitungkan sejumlah faktor lain. Misalnya, seseorang yang menghidupi keluarga akan menghadapi dampak yang lebih besar daripada seseorang yang tidak, karena mereka memiliki pendapatan yang lebih kecil untuk dibelanjakan. Selanjutnya, denda berdasarkan pendapatan mengabaikan kekayaan keseluruhan (yaitu berapa banyak uang yang sebenarnya dimiliki seseorang: seseorang mungkin memiliki banyak aset tetapi tidak memiliki pendapatan tinggi). Proposisi ini tidak mempertimbangkan ketidaksetaraan ini, yang mungkin memiliki efek yang jauh lebih besar, dan oleh karena itu argumen ini diterapkan secara tidak konsisten.

Query argumen tandingan yang ringkas terkait dengan argumen #N:
```

*Output:*
```
hukuman rumah akan membuat denda relatif terhadap pendapatan
```

Secara umum, prompt seperti itu dapat dinyatakan sebagai:

$(e_{prompt}, e_{doc}(d_{1}), e_{query}(q_1), . . . , e_{doc}(d_k), e_{query}(q_k), e_{doc}(d))$

, di mana $e_{doc}$ dan $e_{query}$ masing-masing adalah deskripsi dokumen dan query khusus tugas, $e_{prompt}$ adalah prompt/instruksi khusus tugas untuk ChatGPT/GPT-4, dan $d$ adalah dokumen baru, yang akan digunakan LLM untuk menghasilkan query.

Dari prompt ini, hanya dokumen terakhir $d$ dan query yang dihasilkan yang akan digunakan untuk pelatihan lebih lanjut dari model lokal. Pendekatan ini dapat diterapkan ketika korpus pencarian target $D$ tersedia, tetapi jumlah pasangan query-dokumen yang dianotasi untuk tugas baru terbatas.

Gambaran keseluruhan alur kerja:

<Screenshot src={IMG2} alt="Gambaran Umum Pembuatan Dataset & Pelatihan PROMPTGATOR." />

Sumber Gambar: [Dai et al. (2022)](https://arxiv.org/abs/2209.11755)

Penting untuk menangani anotasi manual contoh secara bertanggung jawab. Lebih baik menyiapkan lebih banyak (misalnya, 20), dan memilih secara acak 2-8 dari mereka untuk prompt. Ini meningkatkan keragaman data yang dihasilkan tanpa biaya waktu yang signifikan dalam anotasi. Namun, contoh-contoh ini harus representatif, diformat dengan benar, dan bahkan merinci hal-hal spesifik seperti panjang query target atau nadanya. Semakin tepat contoh dan instruksi, semakin baik data sintetis akan digunakan untuk melatih Retriever. Contoh few-shot berkualitas rendah dapat berdampak negatif pada kualitas akhir model yang dilatih.

Dalam kebanyakan kasus, menggunakan model yang lebih terjangkau seperti ChatGPT sudah cukup, karena kinerjanya baik dengan domain yang tidak biasa dan bahasa selain bahasa Inggris. Misalnya, prompt dengan instruksi dan 4-5 contoh biasanya memakan 700 token (dengan asumsi setiap bagian tidak lebih dari 128 token karena batasan Retriever) dan generasi adalah 25 token. Jadi, menghasilkan dataset sintetis untuk korpus 50.000 dokumen untuk fine-tuning model lokal akan memakan biaya: `50.000 * (700 * 0,001 * $0,0015 + 25 * 0,001 * $0,002) = 55`, di mana `$0,0015` dan `$0,002` adalah biaya per 1.000 token dalam API GPT-3.5 Turbo. Bahkan mungkin untuk menghasilkan 2-4 contoh query untuk dokumen yang sama. Namun, seringkali manfaat dari pelatihan lebih lanjut sepadan, terutama jika Anda menggunakan Retriever bukan untuk domain umum (seperti pencarian berita dalam bahasa Inggris) tetapi untuk domain spesifik (seperti hukum Republik Ceko, seperti yang disebutkan).

Angka 50.000 bukanlah angka acak. Dalam penelitian oleh [Dai et al. (2022)](https://arxiv.org/abs/2209.11755), dinyatakan bahwa ini adalah jumlah perkiraan data berlabel manual yang dibutuhkan agar model dapat menyamai kualitas yang dilatih pada data sintetis. Bayangkan harus mengumpulkan setidaknya 10.000 contoh sebelum meluncurkan produk Anda! Itu akan memakan waktu tidak kurang dari sebulan, dan biaya tenaga kerja pasti akan melebihi seribu dolar, jauh lebih banyak daripada menghasilkan data sintetis dan melatih model Retriever lokal. Sekarang, dengan teknik yang Anda pelajari hari ini, Anda dapat mencapai pertumbuhan metrik dua digit hanya dalam beberapa hari!

<Screenshot src={IMG3} alt="Dataset Sintetis VS Dataset Berlabel Manual" />

Sumber Gambar: [Dai et al. (2022)](https://arxiv.org/abs/2209.11755)

Dan berikut adalah template prompt dari paper yang sama untuk beberapa dataset dalam benchmark BeIR.

<Screenshot src={IMG4} alt="Template Prompt dari paper PROMPTGATOR." />

Sumber Gambar: [Dai et al. (2022)](https://arxiv.org/abs/2209.11755)

