
# Active-Prompt (Prompt Aktif)

import { Callout, FileTree } from 'nextra-theme-docs'
import {Screenshot} from 'components/screenshot'
import ACTIVE from '../../../img/active-prompt.png'

Metode Chain-of-thought (CoT) atau Rantai Pemikiran bergantung pada serangkaian contoh yang telah dianotasi oleh manusia. Masalahnya, contoh-contoh ini mungkin bukan yang paling efektif untuk berbagai tugas yang berbeda. Untuk mengatasi hal ini, [Diao dkk., (2023)](https://arxiv.org/pdf/2302.12246.pdf) baru-baru ini mengusulkan pendekatan prompting baru yang disebut Active-Prompt (Prompt Aktif) untuk menyesuaikan LLM (Model Bahasa Besar) dengan contoh-contoh prompt yang spesifik untuk tugas tertentu (dilengkapi dengan penalaran CoT yang dirancang oleh manusia).

Berikut adalah ilustrasi pendekatan tersebut. Langkah pertama adalah memberikan pertanyaan kepada LLM dengan atau tanpa beberapa contoh CoT. Sistem kemudian menghasilkan *k* jawaban yang mungkin untuk serangkaian pertanyaan latihan. Selanjutnya, sistem menghitung metrik ketidakpastian berdasarkan *k* jawaban tersebut (menggunakan tingkat ketidaksetujuan antar jawaban). Pertanyaan-pertanyaan dengan ketidakpastian tertinggi dipilih untuk dianotasi oleh manusia. Akhirnya, contoh-contoh baru yang telah dianotasi ini digunakan untuk menjawab setiap pertanyaan.

Pendekatan ini mirip dengan seorang guru yang memilih soal-soal yang paling membingungkan bagi siswa, lalu memberikan penjelasan khusus untuk soal-soal tersebut. Dengan cara ini, LLM dapat "belajar" dari contoh-contoh yang paling relevan dan menantang.

<Screenshot src={ACTIVE} alt="ACTIVE" />
Sumber Gambar: [Diao dkk., (2023)](https://arxiv.org/pdf/2302.12246.pdf)
