

# Mengatasi Keberagaman Dataset yang Dihasilkan

import {Screenshot} from 'components/screenshot'

import IMG1 from '../../img/synthetic_diversity/textbooks_1.png'
import IMG2 from '../../img/synthetic_diversity/textbooks_2.png'

Pada [bab sebelumnya](https://www.promptingguide.ai/applications/synthetic_rag), kita membahas potensi penggunaan LLM (Large Language Model atau Model Bahasa Besar) untuk menghasilkan dataset sintetis. Dataset ini dapat digunakan untuk melatih model Retriever lokal. Metode ini dimungkinkan karena tersedianya banyak dokumen tanpa label. Setiap dokumen digunakan untuk membuat satu atau lebih pertanyaan sintetis, membentuk pasangan pertanyaan-dokumen.

Tapi bagaimana jika tugas Anda bukan Information Retrieval? Misalnya, Anda sedang mengerjakan masalah klasifikasi dokumen hukum tetapi tidak diizinkan mengirim data ke API eksternal. Dalam situasi ini, Anda perlu melatih model lokal. Namun, pengumpulan data bisa menjadi hambatan besar yang menunda pengembangan produk.

Untuk menyederhanakan, anggap tujuannya adalah membuat cerita anak-anak. Tugas ini menjadi titik awal penelitian [Eldan et al. (2023)](https://arxiv.org/abs/2305.07759). Setiap cerita terdiri dari 2-3 paragraf dengan alur dan tema sederhana, sementara keseluruhan dataset mencakup kosakata dan pengetahuan faktual anak-anak.

Bahasa bukan hanya sistem aturan dan simbol; ia menyampaikan dan menafsirkan makna. Tantangan utama menggunakan model bahasa besar untuk menghasilkan data pelatihan adalah memastikan keberagaman dataset. Bahkan dengan [temperature generasi](https://www.promptingguide.ai/introduction/settings) yang tinggi, model dapat menghasilkan dataset yang berulang dan kurang beragam (bahkan untuk bahasa anak-anak). Koherensi dan relevansi juga menjadi tantangan dalam generasi bahasa alami.

Untuk mengatasi masalah keberagaman, para peneliti menyiapkan kosakata sekitar 1500 kata dasar, mencerminkan kosakata anak-anak, dibagi menjadi kata benda, kata kerja, dan kata sifat. Dalam setiap generasi, satu kata kerja, satu kata benda, dan satu kata sifat dipilih secara acak. Model kemudian menghasilkan cerita yang mengintegrasikan kata-kata acak ini.

Teknik ini secara signifikan memperluas keberagaman dataset, memastikan cerita mencakup seluruh kosakata anak-anak dan kombinasi konsep yang beragam. Selain itu, peneliti memasukkan fitur cerita potensial (seperti dialog, plot twist, akhir yang buruk, atau pelajaran moral). Subset acak dari fitur-fitur ini dipilih untuk setiap cerita, dan model diminta untuk menyertakannya.

*Prompt:*
```
Tulis cerita pendek (3-5 paragraf) yang hanya menggunakan kata-kata sangat sederhana yang mungkin dipahami anak usia 3 tahun. Cerita harus menggunakan kata kerja "{random.choice(verbs_list)}", kata benda "{random.choice(nouns_list)}" dan kata sifat "{random.choice(adjectives_list)}". Cerita harus memiliki fitur berikut: {random.choice(features_list)}, {random.choice(features_list)}. Ingat untuk hanya menggunakan kata-kata sederhana!
```

Misalkan celah-celah tersebut diisi sebagai berikut:

*Prompt:*
```
Tulis cerita pendek (3-5 paragraf) yang hanya menggunakan kata-kata sangat sederhana yang mungkin dipahami anak usia 3 tahun. Cerita harus menggunakan kata kerja "menghias", kata benda "petir" dan kata sifat "kuno". Cerita harus memiliki fitur berikut: cerita harus mengandung setidaknya satu dialog, cerita memiliki akhir yang buruk. Ingat untuk hanya menggunakan kata-kata sederhana!
```

*Output:*
```
Dahulu kala, di sebuah rumah kuno, tinggallah seorang gadis bernama Lily. Dia suka menghias kamarnya dengan benda-benda cantik. Suatu hari, dia menemukan kotak besar di loteng. Dia membukanya dan melihat banyak hiasan berkilau. Lily sangat senang dan memutuskan untuk menggunakannya di kamarnya.

Saat Lily sedang menghias kamarnya, langit di luar menjadi gelap. Terdengar suara petir yang keras, dan Lily menjadi takut. Dia berlari ke ibunya dan berkata, "Ibu, petirnya sangat keras!" Ibunya memeluknya dan berkata, "Jangan khawatir, ini akan segera berlalu."

Tapi petir tidak berhenti. Suaranya semakin keras, dan rumah kuno itu mulai bergetar. Tiba-tiba, atap rumah runtuh menimpa hiasan-hiasan cantik itu. Lily sedih karena kamarnya tidak cantik lagi. Selesai.
```

Di sini kita mengandalkan model generasi teks terbaru (GPT-3.5 dan GPT-4), yang dapat menghasilkan konten sintetis dalam jumlah besar, mengikuti instruksi. Karena kita merumuskan prompt secara acak setiap kali, dan model mengikutinya dengan tepat, cerita yang dihasilkan menjadi sangat beragam. Narasi akan sepenuhnya berbeda bahkan jika satu atau dua kata tetap sama. Pada dasarnya, kita menerapkan teknik ini untuk memasukkan keacakan ke dalam prompt, menghasilkan dataset yang beragam.

Anda mendapatkan idenya:

1. Identifikasi parameter/entitas mana yang mungkin bervariasi antara sampel yang berbeda dalam dataset sintetis Anda;
2. Hasilkan atau kumpulkan secara manual kumpulan entitas ini untuk mengisi celah-celah;
3. Hasilkan dataset dengan memilih entitas secara acak untuk dimasukkan. Sebaiknya atur temperature generasi lebih tinggi dari default tetapi di bawah maksimum;
4. Latih model lokal menggunakan hasil generasi ChatGPT/GPT-4.

Penting untuk dicatat bahwa salah satu entitas yang digunakan untuk memulai generasi Anda bisa jadi label kelas. Misalnya, dalam tugas klasifikasi sentimen, Anda dapat langsung menyebutkan "positif" atau "negatif" dalam prompt untuk menerima teks yang dihasilkan dengan label yang sesuai. Kemudian, pengklasifikasi lokal dilatih menggunakan data ini.

# Generasi Data Sintetis Iteratif (Hierarkis)

Format dapat dibuat lebih kompleks dengan menggunakan lebih banyak entitas, beberapa di antaranya dihasilkan sebelumnya oleh LLM itu sendiri. Misalnya, seseorang dapat memulai dengan permintaan untuk menghasilkan ringkasan cerita dan menulis satu kalimat yang harus muncul dalam cerita. Kemudian, gunakan data perantara yang dihasilkan itu dalam permintaan akhir.

*Prompt:*
```
Ringkasan: {ringkasan singkat yang dihasilkan oleh LLM, menggunakan pendekatan di atas}
Fitur: {salin fitur-fitur dari prompt awal}
Kalimat: {kalimat yang dihasilkan oleh LLM, yang harus ada dalam cerita}
Kata-kata: {salin kata-kata dari prompt awal}
Cerita:
```

Contoh prompt yang telah diisi:

*Prompt:*
```
Ringkasan: Lily dan Timmy membangun istana pasir bersama dan belajar berkompromi, tetapi istana itu roboh karena hembusan angin. Mereka menemukan keindahan dalam istana pasir yang rusak dan bermain dengan gembira bersama kupu-kupu.
Fitur: Dialog, Foreshadowing, Twist
Kalimat: Suatu hari, dia pergi ke taman dan melihat kupu-kupu yang cantik.
Kata-kata: tidak setuju, jaringan, indah
Cerita:
```

*Output:*
```
Dahulu kala, ada seorang gadis kecil bernama Lily. Dia suka bermain dengan mainannya dan teman-temannya. Suatu hari, dia pergi ke taman dan melihat kupu-kupu yang cantik. Dia mencoba menangkapnya, tapi kupu-kupu itu terbang menjauh.

Teman Lily, Timmy, datang untuk bermain dengannya. Mereka memutuskan untuk membangun istana pasir, tapi mereka tidak setuju tentang cara membangunnya. Lily ingin membuatnya tinggi, sementara Timmy ingin membuatnya lebar. Mereka berdebat sebentar, tapi akhirnya setuju untuk membuatnya tinggi dan lebar.

Saat mereka membangun istana pasir, mereka melihat sekelompok semut bekerja sama. Mereka menyadari bahwa semut-semut itu sedang membangun jaringan terowongan. Tiba-tiba, hembusan angin datang dan merobohkan istana pasir mereka. Mereka sedih, tapi kemudian mereka melihat kupu-kupu itu lagi. Kupu-kupu itu hinggap di sisa-sisa istana pasir mereka dan mereka menyadari bahwa itu masih indah, bahkan dalam keadaan rusak. Mereka tersenyum dan bermain bersama dengan gembira.
```

Dengan demikian, dimungkinkan untuk menghasilkan ratusan ribu contoh yang sangat beragam untuk melatih model. Misalnya, Anda perlu melatih pengklasifikasi yang menentukan apakah sebuah teks mengandung dialog atau plot twist. Karena prompt awal berisi label, diketahui nilai target mana yang perlu diprediksi untuk setiap sampel yang dihasilkan.

# Buku Teks Adalah Semua yang Anda Butuhkan

Pertanyaan penting yang muncul dari pendekatan ini adalah apakah sintesis dataset benar-benar dapat memberikan manfaat saat melatih jaringan untuk aplikasi dunia nyata. Untungnya, para peneliti telah menangani pertanyaan ini dengan melakukan investigasi mereka sendiri dan memvalidasi efektivitas pelatihan model bahasa yang lebih kecil menggunakan data sintetis yang berasal dari LLM mutakhir.

Dalam studi mereka, [Gunasekar et al. (2023)](https://arxiv.org/abs/2306.11644) menekankan pentingnya data pelatihan berkualitas tinggi dalam model mereka. Mereka berpendapat bahwa model bahasa akan lebih efektif jika dilatih menggunakan materi yang menyerupai karakteristik "buku teks" yang baik: jelas, komprehensif, informatif, dan tidak bias.

Prinsip-prinsip ini menjadi dasar untuk menciptakan dataset semi-sintetis untuk melatih LLM yang disebut Phi-1. Tugas evaluasi utama adalah menghasilkan fungsi Python yang mengikuti deskripsi teks atau docstring yang diberikan. Kualitas model dievaluasi menggunakan benchmark HumanEval ([Chen et al., 2021](https://arxiv.org/abs/2107.03374)).

Para peneliti menekankan pentingnya keberagaman dalam pendekatan ini karena beberapa alasan. Ini memperkenalkan model bahasa ke berbagai ekspresi koding dan pendekatan pemecahan masalah, mengurangi risiko overfitting atau ketergantungan pada pola tertentu, dan meningkatkan kemampuan model untuk menangani tugas-tugas yang tidak familiar atau inovatif.

Untuk mengatasi tantangan penulisan kode, para peneliti membuat dokumen mirip buku teks yang berfokus pada topik-topik yang mendorong penalaran dan keterampilan algoritma dasar. Mereka mencapai keberagaman dengan menerapkan batasan pada:

- topik
- target audiens

Sayangnya, para peneliti tidak memberikan informasi spesifik tentang template prompt yang digunakan untuk menghasilkan data sintetis. Namun, mereka memang mendemonstrasikan output yang dihasilkan. Mereka memilih untuk menggunakan ChatGPT (GPT-3.5) alih-alih GPT-4, dan bahkan strategi ini menghasilkan hasil yang sangat baik saat mereka melakukan fine-tuning model menggunakan data sintetis.

<Screenshot src={IMG1} alt="Contoh sampel mirip buku teks yang dihasilkan" />

Sumber Gambar: [Gunasekar et al. (2023)](https://arxiv.org/abs/2306.11644)

Penting untuk memperhatikan batasan target audiens. Menentukan target audiens adalah cara yang sangat baik untuk meningkatkan keberagaman data sintetis. Seorang siswa SMA, mahasiswa S1 Ilmu Komputer, dan kandidat PhD tentu merumuskan penjelasan dan memproses informasi secara berbeda, membuat data yang dihasilkan menjadi lebih beragam. Mari kita coba merekonstruksi promptnya.

*Prompt:*
```
Tulis sebuah ekstrak dari buku teks Ilmu Komputer untuk mahasiswa tahun pertama S1. Bahasa pemrograman yang digunakan adalah Python 3.6.

Ini adalah ekstrak dari bagian tengah topik berikut: Matriks singular.

Ekstrak dimulai dengan gambaran umum tingkat tinggi tentang topik tersebut. Kemudian, disajikan sebuah contoh dan dijelaskan solusinya dalam bahasa alami. Setelah itu, berikan 1-2 cuplikan kode, mengikuti contoh tersebut. Setiap cuplikan tidak lebih dari 10 baris. Tidak boleh ada teks setelah cuplikan kode.

Ingat bahwa ekstrak harus ringkas dan hanya menjelaskan satu konsep pada satu waktu. Kode harus merepresentasikan fungsi Python & pemanggilannya. Semua pustaka ML/DS umum tersedia.

Jangan terlalu bertele-tele. Panjang ekstrak yang diharapkan adalah maksimal 2 paragraf.
```

*Output:*
```
**Matriks Singular**

Dalam aljabar linear, sebuah matriks disebut "singular" jika tidak memiliki invers. Definisi lain yang setara adalah ketika determinan matriks tersebut nol. Matriks singular penting karena mereka merepresentasikan sistem persamaan linear yang tidak memiliki solusi unik.

Perhatikan matriks 2x2 `[[a, b], [c, d]]`. Jika hasil kali `ad` dan `bc` sama (yaitu, `ad = bc`), maka matriks ini singular. Mari kita eksplorasi dengan contoh: diberikan matriks `[[2, 4], [1, 2]]`, Anda akan menemukan bahwa hasil kali diagonal menghasilkan hasil yang sama (2 * 2 = 4 * 1), sehingga ini adalah matriks singular.

import numpy as np

def is_singular(matrix):
    determinant = np.linalg.det(matrix)
    return abs(determinant) < 1e-9

matrix_example = np.array([[2, 4], [1, 2]])
print(is_singular(matrix_example))  # mengembalikan True
```

Cukup mirip!

Secara total, para peneliti menghasilkan 1 miliar token untuk memperkaya set pelatihan model, memungkinkan model yang lebih kecil (hanya 1,5 miliar parameter) untuk bersaing dengan model yang sepuluh kali lebih besar (untuk detailnya, lihat artikel [Gunasekar et al. (2023)](https://arxiv.org/abs/2306.11644)).

<Screenshot src={IMG2} alt="Metrik Phi-1, dibandingkan dengan model yang lebih besar." />

Sumber Gambar: [Gunasekar et al. (2023)](https://arxiv.org/abs/2306.11644)

Untuk tugas Anda, mungkin tidak diperlukan jumlah data sintetis sebanyak itu (karena para peneliti mempelajari pretraining, yang membutuhkan sumber daya signifikan). Namun, bahkan sebagai perkiraan, dengan harga `$0,002` per 1000 token (harga standar ChatGPT), akan menghabiskan biaya `$2000` untuk token yang dihasilkan dan sekitar jumlah yang sama untuk prompt.

Perlu diingat bahwa fine-tuning pada data sintetis menjadi lebih berharga ketika domain semakin spesifik, terutama jika bahasanya menyimpang dari bahasa Inggris (di antara faktor-faktor lain). Selain itu, metode ini bekerja dengan baik dengan [Chain-of-Thought (CoT)](https://www.promptingguide.ai/techniques/cot), membantu model lokal meningkatkan kemampuan penalarannya. Teknik prompting lainnya juga berfungsi. Dan jangan lupa bahwa model open-source seperti Alpaca ([Taori et al., (2023)](https://crfm.stanford.edu/2023/03/13/alpaca.html)) dan Vicuna ([Zheng et al., (2023)](https://lmsys.org/blog/2023-03-30-vicuna/)) unggul melalui fine-tuning pada data sintetis.

