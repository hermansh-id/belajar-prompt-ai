
# Pemanggilan Fungsi dengan LLM (Model Bahasa Besar)

import {Cards, Card} from 'nextra-theme-docs'
import {CodeIcon} from 'components/icons'

## Memulai dengan Pemanggilan Fungsi

<iframe width="100%"
  height="415px"
  src="https://www.youtube.com/embed/p0I-hwZSWMs?si=tQgi-LiHe6Oj_rzm" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture"
  allowFullScreen
  />

Pemanggilan fungsi adalah kemampuan untuk menghubungkan LLM dengan alat eksternal secara andal. Ini memungkinkan penggunaan alat yang efektif dan interaksi dengan API eksternal.

LLM seperti GPT-4 dan GPT-3.5 telah dilatih khusus untuk mendeteksi kapan sebuah fungsi perlu dipanggil. Mereka kemudian menghasilkan JSON yang berisi argumen untuk memanggil fungsi tersebut. Fungsi-fungsi ini bertindak sebagai alat dalam aplikasi AI Anda, dan Anda bisa mendefinisikan lebih dari satu dalam satu permintaan.

Pemanggilan fungsi sangat penting untuk membuat chatbot atau agen berbasis LLM. Mereka membutuhkan ini untuk mengambil konteks atau berinteraksi dengan alat eksternal dengan mengubah bahasa alami menjadi panggilan API.

Dengan pemanggilan fungsi, pengembang bisa membuat:

- Agen percakapan yang bisa menggunakan alat eksternal untuk menjawab pertanyaan. Misalnya, pertanyaan "Bagaimana cuaca di Bali?" akan diubah menjadi panggilan fungsi seperti `dapatkan_cuaca_saat_ini(lokasi: string, satuan: 'celsius' | 'fahrenheit')`
- Solusi berbasis LLM untuk mengekstrak dan menandai data (contohnya, mengekstrak nama orang dari artikel Wikipedia)
- Aplikasi yang bisa mengubah bahasa alami menjadi panggilan API atau kueri database yang valid
- Mesin pencari pengetahuan percakapan yang berinteraksi dengan basis pengetahuan

Dalam panduan ini, kami akan menunjukkan cara memberi prompt kepada model seperti GPT-4 dan model open-source untuk melakukan pemanggilan fungsi dalam berbagai kasus penggunaan.

## Pemanggilan Fungsi dengan GPT-4

Mari kita ambil contoh sederhana: kita meminta model untuk memeriksa cuaca di lokasi tertentu.

LLM sendiri tidak bisa menjawab permintaan ini karena ia dilatih dengan dataset yang memiliki batas waktu. Cara mengatasinya adalah dengan menggabungkan LLM dengan alat eksternal. Anda bisa memanfaatkan kemampuan pemanggilan fungsi model untuk menentukan fungsi eksternal yang akan dipanggil beserta argumennya, lalu membuatnya memberikan respons akhir. Berikut adalah contoh sederhana cara melakukannya menggunakan API OpenAI.

Misalkan pengguna mengajukan pertanyaan berikut kepada model:

```
Bagaimana cuaca di Jakarta?
```

Untuk menangani permintaan ini menggunakan pemanggilan fungsi, langkah pertama adalah mendefinisikan fungsi cuaca atau serangkaian fungsi yang akan Anda sertakan sebagai bagian dari permintaan API OpenAI:

```python
tools = [
    {
        "type": "function",
        "function": {
            "name": "dapatkan_cuaca_saat_ini",
            "description": "Dapatkan cuaca saat ini di lokasi tertentu",
            "parameters": {
                "type": "object",
                "properties": {
                    "lokasi": {
                        "type": "string",
                        "description": "Kota dan provinsi, misalnya Jakarta, DKI Jakarta",
                    },
                    "satuan": {
                        "type": "string", 
                        "enum": ["celsius", "fahrenheit"]},
                },
                "required": ["lokasi"],
            },
        },   
    }
]
```

Fungsi `dapatkan_cuaca_saat_ini` mengembalikan cuaca saat ini di lokasi tertentu. Ketika Anda menyertakan definisi fungsi ini dalam permintaan, fungsi tersebut tidak benar-benar dijalankan. Ia hanya mengembalikan objek JSON yang berisi argumen yang diperlukan untuk memanggil fungsi. Berikut adalah beberapa cuplikan kode tentang cara melakukannya.

Anda bisa mendefinisikan fungsi penyelesaian seperti ini:

```python
def dapatkan_penyelesaian(pesan, model="gpt-3.5-turbo-1106", temperature=0, max_tokens=300, tools=None):
    respons = openai.chat.completions.create(
        model=model,
        messages=pesan,
        temperature=temperature,
        max_tokens=max_tokens,
        tools=tools
    )
    return respons.choices[0].message
```

Beginilah cara Anda bisa menyusun pertanyaan pengguna:

```python
pesan = [
    {
        "role": "user",
        "content": "Bagaimana cuaca di Jakarta?"
    }
]
```

Terakhir, Anda bisa memanggil fungsi `dapatkan_penyelesaian` di atas dan menyertakan `pesan` dan `tools`:

```python
respons = dapatkan_penyelesaian(pesan, tools=tools)
```

Objek `respons` berisi hal berikut:

```python
ChatCompletionMessage(content=None, role='assistant', function_call=None, tool_calls=[ChatCompletionMessageToolCall(id='...', function=Function(arguments='{"lokasi":"Jakarta","satuan":"celsius"}', name='dapatkan_cuaca_saat_ini'), type='function')])
```

Khususnya, objek `arguments` berisi argumen penting yang diekstrak oleh model dan akan diperlukan untuk menyelesaikan permintaan.

Anda kemudian bisa memilih untuk memanggil API cuaca eksternal untuk mendapatkan cuaca yang sebenarnya. Setelah Anda memiliki informasi cuaca, Anda bisa mengirimkannya kembali ke model untuk merangkum respons akhir berdasarkan pertanyaan asli pengguna.

## Notebook

Berikut adalah notebook dengan contoh sederhana yang menunjukkan cara menggunakan pemanggilan fungsi dengan API OpenAI:

<Cards>
    <Card 
        icon={<CodeIcon />}
        title="Pemanggilan Fungsi dengan API OpenAI"
        href="https://github.com/dair-ai/Prompt-Engineering-Guide/blob/main/notebooks/pe-function-calling.ipynb"
    />
</Cards>

## Pemanggilan Fungsi dengan LLM Open-Source
Catatan lebih lanjut tentang pemanggilan fungsi dengan LLM open-source akan segera hadir.

## Kasus Penggunaan Pemanggilan Fungsi

Berikut adalah daftar kasus penggunaan yang bisa mendapat manfaat dari kemampuan pemanggilan fungsi LLM:

- **Agen Percakapan**: Pemanggilan fungsi bisa digunakan untuk membuat agen percakapan atau chatbot kompleks yang menjawab pertanyaan rumit dengan memanggil API eksternal atau basis pengetahuan eksternal dan memberikan respons yang lebih relevan dan berguna.

- **Pemahaman Bahasa Alami**: Ini bisa mengubah bahasa alami menjadi data JSON terstruktur, mengekstrak data terstruktur dari teks, dan melakukan tugas seperti pengenalan entitas bernama, analisis sentimen, dan ekstraksi kata kunci.

- **Pemecahan Masalah Matematika**: Pemanggilan fungsi bisa digunakan untuk mendefinisikan fungsi khusus untuk memecahkan masalah matematika kompleks yang memerlukan beberapa langkah dan berbagai jenis perhitungan lanjutan.

- **Integrasi API**: Ini bisa digunakan untuk mengintegrasikan LLM dengan API eksternal secara efektif untuk mengambil data atau melakukan tindakan berdasarkan input. Ini bisa membantu membangun sistem tanya jawab atau asisten kreatif. Secara umum, pemanggilan fungsi bisa mengubah bahasa alami menjadi panggilan API yang valid.

- **Ekstraksi Informasi**: Pemanggilan fungsi bisa digunakan secara efektif untuk mengekstrak informasi spesifik dari input tertentu, seperti mengambil berita atau referensi yang relevan dari sebuah artikel.

## Referensi
- [Fireworks Meningkatkan Standar Kualitas dengan Peluncuran Model dan API Pemanggilan Fungsi](https://blog.fireworks.ai/fireworks-raises-the-quality-bar-with-function-calling-model-and-api-release-e7f49d1e98e9)
- [Benchmarking Penggunaan Alat Agen dan Pemanggilan Fungsi](https://blog.langchain.dev/benchmarking-agent-tool-use/)
- [Pemanggilan Fungsi](https://ai.google.dev/docs/function_calling)
- [Berinteraksi dengan API](https://python.langchain.com/docs/use_cases/apis)
- [Pemanggilan Fungsi OpenAI](https://platform.openai.com/docs/guides/function-calling)
- [Cara memanggil fungsi dengan model chat](https://cookbook.openai.com/examples/how_to_call_functions_with_chat_models)
- [Mendorong Dukungan Data Terstruktur ChatGPT ke Batasnya](https://minimaxir.com/2023/12/chatgpt-structured-data/)
- [Pemecahan Masalah Matematika dengan Pemanggilan Fungsi](https://github.com/svpino/openai-function-calling/blob/main/sample.ipynb)
